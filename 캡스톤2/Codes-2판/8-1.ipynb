{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>880</td>\n",
       "      <td>476</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>716</td>\n",
       "      <td>204</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>276</td>\n",
       "      <td>1090</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>13</td>\n",
       "      <td>225</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>12</td>\n",
       "      <td>203</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  movie_id  rating\n",
       "0          196       242       3\n",
       "1          186       302       3\n",
       "2           22       377       1\n",
       "3          244        51       2\n",
       "4          166       346       1\n",
       "...        ...       ...     ...\n",
       "99995      880       476       3\n",
       "99996      716       204       5\n",
       "99997      276      1090       1\n",
       "99998       13       225       2\n",
       "99999       12       203       3\n",
       "\n",
       "[100000 rows x 3 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Created or modified on May 2022\n",
    "# Author: 임일\n",
    "# Hybrid 추천 - Dummy engine 사용\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# csv 파일에서 불러오기\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "ratings = pd.read_csv('C:/RecoSys/Data/u.data', names=r_cols,  sep='\\t',encoding='latin-1')\n",
    "ratings = ratings[['user_id', 'movie_id', 'rating']].astype(int)            # timestamp 제거\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train test 분리\n",
    "TRAIN_SIZE = 0.75\n",
    "ratings = shuffle(ratings, random_state=1)\n",
    "cutoff = int(TRAIN_SIZE * len(ratings))\n",
    "ratings_train = ratings.iloc[:cutoff]\n",
    "ratings_test = ratings.iloc[cutoff:]\n",
    "\n",
    "# RMSE 계산을 위한 함수\n",
    "def RMSE2(y_true, y_pred):\n",
    "    return np.sqrt(np.mean((np.array(y_true) - np.array(y_pred))**2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##### (1)\n",
    "\n",
    "# Dummy recommender 0\n",
    "def recommender0(recomm_list):\n",
    "    recommendations = []\n",
    "    for pair in recomm_list:\n",
    "        recommendations.append(random.random() * 4 + 1)\n",
    "    return np.array(recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dummy recommender 1\n",
    "def recommender1(recomm_list):\n",
    "    recommendations = []\n",
    "    for pair in recomm_list:\n",
    "        recommendations.append(random.random() * 4 + 1)\n",
    "    return np.array(recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.90790544 1.22286727 1.35643156 ... 3.75538471 3.72333224 1.82447057]\n",
      "[1.00569438 2.98412449 1.0251409  ... 4.17442592 4.75939775 2.79721373]\n",
      "[4.12746323 1.57511871 1.29017343 ... 3.83919295 3.93054534 2.0190192 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.562749803626184"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Hybrid 결과 얻기\n",
    "weight = [0.8, 0.2]\n",
    "recomm_list = np.array(ratings_test)\n",
    "predictions0 = recommender0(recomm_list)\n",
    "print(predictions0)\n",
    "predictions1 = recommender1(recomm_list)\n",
    "\n",
    "print(predictions1)\n",
    "predictions = predictions0 * weight[0] + predictions1 * weight[1]\n",
    "print(predictions)\n",
    "RMSE2(recomm_list[:, 2], predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10 ; Train RMSE = 0.9664 ; Test RMSE = 0.9833\n",
      "Iteration: 20 ; Train RMSE = 0.9420 ; Test RMSE = 0.9644\n",
      "Iteration: 30 ; Train RMSE = 0.9313 ; Test RMSE = 0.9566\n",
      "Iteration: 40 ; Train RMSE = 0.9253 ; Test RMSE = 0.9523\n",
      "Iteration: 50 ; Train RMSE = 0.9214 ; Test RMSE = 0.9497\n",
      "Iteration: 60 ; Train RMSE = 0.9186 ; Test RMSE = 0.9480\n",
      "Iteration: 70 ; Train RMSE = 0.9165 ; Test RMSE = 0.9468\n",
      "Iteration: 80 ; Train RMSE = 0.9147 ; Test RMSE = 0.9459\n",
      "Iteration: 90 ; Train RMSE = 0.9130 ; Test RMSE = 0.9451\n",
      "Iteration: 100 ; Train RMSE = 0.9112 ; Test RMSE = 0.9444\n",
      "Iteration: 110 ; Train RMSE = 0.9088 ; Test RMSE = 0.9435\n",
      "Iteration: 120 ; Train RMSE = 0.9057 ; Test RMSE = 0.9423\n",
      "Iteration: 130 ; Train RMSE = 0.9012 ; Test RMSE = 0.9406\n",
      "Iteration: 140 ; Train RMSE = 0.8948 ; Test RMSE = 0.9382\n",
      "Iteration: 150 ; Train RMSE = 0.8862 ; Test RMSE = 0.9350\n",
      "Iteration: 160 ; Train RMSE = 0.8756 ; Test RMSE = 0.9313\n",
      "Iteration: 170 ; Train RMSE = 0.8632 ; Test RMSE = 0.9276\n",
      "Iteration: 180 ; Train RMSE = 0.8495 ; Test RMSE = 0.9240\n",
      "Iteration: 190 ; Train RMSE = 0.8344 ; Test RMSE = 0.9207\n",
      "Iteration: 200 ; Train RMSE = 0.8176 ; Test RMSE = 0.9178\n",
      "Iteration: 210 ; Train RMSE = 0.7992 ; Test RMSE = 0.9151\n",
      "Iteration: 220 ; Train RMSE = 0.7792 ; Test RMSE = 0.9130\n",
      "Iteration: 230 ; Train RMSE = 0.7579 ; Test RMSE = 0.9114\n",
      "Iteration: 240 ; Train RMSE = 0.7353 ; Test RMSE = 0.9103\n",
      "Iteration: 250 ; Train RMSE = 0.7120 ; Test RMSE = 0.9098\n"
     ]
    }
   ],
   "source": [
    "# Created or modified on May 2022\n",
    "# Author: 임일\n",
    "# Hybrid 추천 - CF + MF\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# 데이터 읽어 오기 \n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "ratings = pd.read_csv('C:/RecoSys/Data/u.data', names=r_cols,  sep='\\t',encoding='latin-1')\n",
    "ratings = ratings[['user_id', 'movie_id', 'rating']].astype(int)            # timestamp 제거\n",
    "\n",
    "# train test 분리\n",
    "TRAIN_SIZE = 0.75\n",
    "ratings = shuffle(ratings, random_state=1)\n",
    "cutoff = int(TRAIN_SIZE * len(ratings))\n",
    "ratings_train = ratings.iloc[:cutoff]\n",
    "ratings_test = ratings.iloc[cutoff:]\n",
    "\n",
    "# 정확도(RMSE)를 계산하는 함수 \n",
    "def RMSE2(y_true, y_pred):\n",
    "    return np.sqrt(np.mean((np.array(y_true) - np.array(y_pred))**2))\n",
    "\n",
    "##### CF 추천 알고리즘 >>>>>>>>>>>>>>>\n",
    "\n",
    "rating_matrix = ratings_train.pivot(index='user_id', columns='movie_id', values='rating')\n",
    "\n",
    "# train set 사용자들의 Cosine similarities 계산\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "matrix_dummy = rating_matrix.copy().fillna(0)\n",
    "user_similarity = cosine_similarity(matrix_dummy, matrix_dummy)\n",
    "user_similarity = pd.DataFrame(user_similarity, index=rating_matrix.index, columns=rating_matrix.index)\n",
    "\n",
    "# train 데이터의 user의 rating 평균과 영화의 평점편차 계산 \n",
    "rating_mean = rating_matrix.mean(axis=1)\n",
    "rating_bias = (rating_matrix.T - rating_mean).T\n",
    "\n",
    "def CF_knn_bias(user_id, movie_id, neighbor_size=0):\n",
    "    if movie_id in rating_bias:\n",
    "        sim_scores = user_similarity[user_id]\n",
    "        movie_ratings = rating_bias[movie_id]\n",
    "        none_rating_idx = movie_ratings[movie_ratings.isnull()].index\n",
    "        movie_ratings = movie_ratings.drop(none_rating_idx)\n",
    "        sim_scores = sim_scores.drop(none_rating_idx)\n",
    "        if neighbor_size == 0:\n",
    "            prediction = np.dot(sim_scores, movie_ratings) / sim_scores.sum()\n",
    "            prediction = prediction + rating_mean[user_id]\n",
    "        else:\n",
    "            if len(sim_scores) > 1:\n",
    "                neighbor_size = min(neighbor_size, len(sim_scores))\n",
    "                sim_scores = np.array(sim_scores)\n",
    "                movie_ratings = np.array(movie_ratings)\n",
    "                user_idx = np.argsort(sim_scores)\n",
    "                sim_scores = sim_scores[user_idx][-neighbor_size:]\n",
    "                movie_ratings = movie_ratings[user_idx][-neighbor_size:]\n",
    "                prediction = np.dot(sim_scores, movie_ratings) / sim_scores.sum()\n",
    "                prediction = prediction + rating_mean[user_id]\n",
    "            else:\n",
    "                prediction = rating_mean[user_id]\n",
    "    else:\n",
    "        prediction = rating_mean[user_id]\n",
    "    return prediction\n",
    "\n",
    "\n",
    "##### MF 추천 알고리즘 >>>>>>>>>>>>>>>\n",
    "\n",
    "class NEW_MF():\n",
    "    def __init__(self, ratings, K, alpha, beta, iterations, verbose=True):\n",
    "        self.R = np.array(ratings)\n",
    "        item_id_index = []\n",
    "        index_item_id = []\n",
    "        for i, one_id in enumerate(ratings):\n",
    "            item_id_index.append([one_id, i])\n",
    "            index_item_id.append([i, one_id])\n",
    "        self.item_id_index = dict(item_id_index)\n",
    "        self.index_item_id = dict(index_item_id)        \n",
    "        user_id_index = []\n",
    "        index_user_id = []\n",
    "        for i, one_id in enumerate(ratings.T):\n",
    "            user_id_index.append([one_id, i])\n",
    "            index_user_id.append([i, one_id])\n",
    "        self.user_id_index = dict(user_id_index)\n",
    "        self.index_user_id = dict(index_user_id)\n",
    "        self.num_users, self.num_items = np.shape(self.R)\n",
    "        self.K = K\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.iterations = iterations\n",
    "        self.verbose = verbose\n",
    "\n",
    "    # train set의 RMSE 계산\n",
    "    def rmse(self):\n",
    "        xs, ys = self.R.nonzero()\n",
    "        self.predictions = []\n",
    "        self.errors = []\n",
    "        for x, y in zip(xs, ys):\n",
    "            prediction = self.get_prediction(x, y)\n",
    "            self.predictions.append(prediction)\n",
    "            self.errors.append(self.R[x, y] - prediction)\n",
    "        self.predictions = np.array(self.predictions)\n",
    "        self.errors = np.array(self.errors)\n",
    "        return np.sqrt(np.mean(self.errors**2))\n",
    "\n",
    "    # Ratings for user i and item j\n",
    "    def get_prediction(self, i, j):\n",
    "        prediction = self.b + self.b_u[i] + self.b_d[j] + self.P[i, :].dot(self.Q[j, :].T)\n",
    "        return prediction\n",
    "\n",
    "    # Stochastic gradient descent to get optimized P and Q matrix\n",
    "    def sgd(self):\n",
    "        for i, j, r in self.samples:\n",
    "            prediction = self.get_prediction(i, j)\n",
    "            e = (r - prediction)\n",
    "\n",
    "            self.b_u[i] += self.alpha * (e - self.beta * self.b_u[i])\n",
    "            self.b_d[j] += self.alpha * (e - self.beta * self.b_d[j])\n",
    "\n",
    "            self.P[i, :] += self.alpha * (e * self.Q[j, :] - self.beta * self.P[i,:])\n",
    "            self.Q[j, :] += self.alpha * (e * self.P[i, :] - self.beta * self.Q[j,:])\n",
    "\n",
    "    # Test set을 선정\n",
    "    def set_test(self, ratings_test):\n",
    "        test_set = []\n",
    "        for i in range(len(ratings_test)):\n",
    "            x = self.user_id_index[ratings_test.iloc[i, 0]]\n",
    "            y = self.item_id_index[ratings_test.iloc[i, 1]]\n",
    "            z = ratings_test.iloc[i, 2]\n",
    "            test_set.append([x, y, z])\n",
    "            self.R[x, y] = 0                    # Setting test set ratings to 0\n",
    "        self.test_set = test_set\n",
    "        return test_set                         # Return test set\n",
    "\n",
    "    # Test set의 RMSE 계산\n",
    "    def test_rmse(self):\n",
    "        error = 0\n",
    "        for one_set in self.test_set:\n",
    "            predicted = self.get_prediction(one_set[0], one_set[1])\n",
    "            error += pow(one_set[2] - predicted, 2)\n",
    "        return np.sqrt(error/len(self.test_set))\n",
    "\n",
    "    # Training 하면서 test set의 정확도를 계산\n",
    "    def test(self):\n",
    "        # Initializing user-feature and item-feature matrix\n",
    "        self.P = np.random.normal(scale=1./self.K, size=(self.num_users, self.K))\n",
    "        self.Q = np.random.normal(scale=1./self.K, size=(self.num_items, self.K))\n",
    "\n",
    "        # Initializing the bias terms\n",
    "        self.b_u = np.zeros(self.num_users)\n",
    "        self.b_d = np.zeros(self.num_items)\n",
    "        self.b = np.mean(self.R[self.R.nonzero()])\n",
    "\n",
    "        # List of training samples\n",
    "        rows, columns = self.R.nonzero()\n",
    "        self.samples = [(i, j, self.R[i,j]) for i, j in zip(rows, columns)]\n",
    "\n",
    "        # Stochastic gradient descent for given number of iterations\n",
    "        training_process = []\n",
    "        for i in range(self.iterations):\n",
    "            np.random.shuffle(self.samples)\n",
    "            self.sgd()\n",
    "            rmse1 = self.rmse()\n",
    "            rmse2 = self.test_rmse()\n",
    "            training_process.append((i+1, rmse1, rmse2))\n",
    "            if self.verbose:\n",
    "                if (i+1) % 10 == 0:\n",
    "                    print(\"Iteration: %d ; Train RMSE = %.4f ; Test RMSE = %.4f\" % (i+1, rmse1, rmse2))\n",
    "        return training_process\n",
    "\n",
    "    # Ratings for given user_id and item_id\n",
    "    def get_one_prediction(self, user_id, item_id):\n",
    "        prediction = self.get_prediction(self.user_id_index[user_id], self.item_id_index[item_id])\n",
    "        return prediction\n",
    "\n",
    "    # Full user-movie rating matrix\n",
    "    def full_prediction(self):\n",
    "        return self.b + self.b_u[:,np.newaxis] + self.b_d[np.newaxis,:] + self.P.dot(self.Q.T)\n",
    "\n",
    "# MF클래스 생성 및 학습\n",
    "R_temp = ratings.pivot(index='user_id', columns='movie_id', values='rating').fillna(0)\n",
    "mf = NEW_MF(R_temp, K=200, alpha=0.001, beta=0.02, iterations=250, verbose=True)\n",
    "test_set = mf.set_test(ratings_test)\n",
    "result = mf.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9467199341641682"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "##### Hybrid 추천 알고리즘\n",
    "\n",
    "def recommender0(recomm_list, mf):\n",
    "    recommendations = np.array([mf.get_one_prediction(user, movie) for (user, movie) in recomm_list])\n",
    "    return recommendations\n",
    "\n",
    "def recommender1(recomm_list, neighbor_size=0):\n",
    "    recommendations = np.array([CF_knn_bias(user, movie, neighbor_size) for (user, movie) in recomm_list])\n",
    "    return recommendations\n",
    "\n",
    "recomm_list = np.array(ratings_test.iloc[:, [0, 1]])\n",
    "predictions0 = recommender0(recomm_list, mf)\n",
    "RMSE2(ratings_test.iloc[:, 2], predictions0)\n",
    "predictions1 = recommender1(recomm_list, 37)\n",
    "RMSE2(ratings_test.iloc[:, 2], predictions1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "weight = [0.8, 0.2]\n",
    "predictions = predictions0 * weight[0] + predictions1 * weight[1]\n",
    "RMSE2(ratings_test.iloc[:, 2], predictions)\n",
    "\n",
    "for i in np.arange(0, 1, 0.01):\n",
    "    weight = [i, 1.0 - i]\n",
    "    predictions = predictions0 * weight[0] + predictions1 * weight[1]\n",
    "    print(\"Weights - %.2f : %.2f ; RMSE = %.7f\" % (weight[0], \n",
    "           weight[1], RMSE2(ratings_test.iloc[:, 2], predictions)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
